{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import gc\n",
    "\n",
    "import xgboost\n",
    "\n",
    "from tqdm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_ROOT = \"/media/felipe/SSD_VOLUME//instacart/\"\n",
    "PICKLE_ROOT = DATA_ROOT+\"pickles/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aisles_df = pd.read_csv(DATA_ROOT+\"aisles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_items_ordered_df = pd.read_csv(DATA_ROOT+'/order_products__train.csv', engine='c', \n",
    "                       dtype={'order_id': np.int32, 'product_id': np.int32, \n",
    "                              'add_to_cart_order': np.uint8, 'reordered': np.uint8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df = pd.read_csv(DATA_ROOT+'/orders.csv', engine='c', dtype={'order_id': np.int32, \n",
    "                                                           'user_id': np.int32, \n",
    "                                                           'order_number': np.int32, \n",
    "                                                           'order_dow': np.uint8, \n",
    "                                                           'order_hour_of_day': np.uint8, \n",
    "                                                           'days_since_prior_order': np.float16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orders_df['days_since_prior_order'] = orders_df['days_since_prior_order'].values.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "departments_df = pd.read_csv(DATA_ROOT+\"/departments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products_df = pd.read_csv(DATA_ROOT+\"/products.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df['product_name'] = products_df['product_name'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prior_items_ordered_df = pd.read_csv(DATA_ROOT+'/order_products__prior.csv', engine='c', \n",
    "                       dtype={'order_id': np.int32, \n",
    "                              'product_id': np.int32, \n",
    "                              'add_to_cart_order': np.uint8, \n",
    "                              'reordered': np.uint8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "orders_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = orders_df[[\"user_id\"]]\n",
    "users_df = users_df.drop_duplicates().reset_index().drop('index',axis=1)\n",
    "users_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## what is the static reorder_factor for each Product, for each product ever re-ordered by each user, in the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EVAL_SET='test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_in_test_set_df = pd.merge(\n",
    "    orders_df.query(\"eval_set == '{}'\".format(EVAL_SET)),\n",
    "    users_df,\n",
    "    on='user_id',\n",
    "    how='left'\n",
    ")[[\"user_id\"]]\n",
    "users_in_test_set_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products_df['rsum']=last_items_ordered_df.groupby('product_id')['reordered'].sum()\n",
    "#Add a field to calculate the total times the item could have been reordered\n",
    "products_df['rtotal']=last_items_ordered_df.groupby('product_id')['reordered'].count()\n",
    "#Add a field to calculate the probability that the item was reordered\n",
    "products_df['prob']=products_df['rsum']/products_df['rtotal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Merge all of the details into a goods page\n",
    "goods = pd.merge(left=pd.merge(left=products_df, right=departments_df, how='left'), right=aisles_df, how='left')\n",
    "# to retain '-' and make product names more \"standard\"\n",
    "goods.product_name = goods.product_name.str.replace(' ', '_').str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goods.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge train and prior together iteratively, to fit into 8GB kernel RAM\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "# initialize it with train dataset\n",
    "order_details = pd.merge(\n",
    "                left=prior_items_ordered_df,\n",
    "                 right=orders_df, \n",
    "                 how='left', \n",
    "                 on='order_id'\n",
    "        ).apply(partial(pd.to_numeric, errors='ignore', downcast='integer'))\n",
    "\n",
    "# add order hierarchy\n",
    "order_details = pd.merge(\n",
    "                left=order_details,\n",
    "                right=goods[['product_id', \n",
    "                             'aisle_id', \n",
    "                             'department_id',\n",
    "                             'prob']].apply(partial(pd.to_numeric, ##Added the 'prob'\n",
    "                                                             errors='ignore', \n",
    "                                                             downcast='integer')),\n",
    "                how='left',\n",
    "                on='product_id'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_details.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split df indexes into parts\n",
    "indexes = np.linspace(0, len(prior_items_ordered_df), num=10, dtype=np.int32)\n",
    "\n",
    "# update by small portions\n",
    "for i in range(len(indexes)-1):\n",
    "    order_details = pd.concat(\n",
    "        [   \n",
    "            order_details,\n",
    "            pd.merge(left=pd.merge(\n",
    "                            left=prior_items_ordered_df.loc[indexes[i]:indexes[i+1], :],\n",
    "                            right=goods[['product_id', \n",
    "                                         'aisle_id', \n",
    "                                         'department_id' ]].apply(partial(pd.to_numeric, \n",
    "                                                                          errors='ignore', \n",
    "                                                                          downcast='integer')),\n",
    "                            how='left',\n",
    "                            on='product_id'\n",
    "                            ),\n",
    "                     right=orders_df, \n",
    "                     how='left', \n",
    "                     on='order_id'\n",
    "                ) #.apply(partial(pd.to_numeric, errors='ignore', downcast='integer'))\n",
    "        ]\n",
    "    )\n",
    "        \n",
    "print('Datafame length: {}'.format(order_details.shape[0]))\n",
    "print('Memory consumption: {:.2f} Mb'.format(sum(order_details.memory_usage(index=True, \n",
    "                                                                         deep=True) / 2**20)))\n",
    "# check dtypes to see if we use memory effectively\n",
    "print(order_details.dtypes)\n",
    "\n",
    "# make sure we didn't forget to retain test dataset :D\n",
    "test_orders = orders_df[orders_df.eval_set == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "order_details = pd.merge(order_details,\n",
    "                         users_in_test_set_df,\n",
    "                         on='user_id',\n",
    "                         how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Datafame length: {}'.format(order_details.shape[0]))\n",
    "print('Memory consumption: {:.2f} Mb'.format(sum(order_details.memory_usage(index=True, \n",
    "                                                                         deep=True) / 2**20)))\n",
    "# check dtypes to see if we use memory effectively\n",
    "print(order_details.dtypes)\n",
    "\n",
    "# make sure we didn't forget to retain test dataset :D\n",
    "test_orders = orders_df[orders_df.eval_set == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_details.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(set(order_details.order_id))[:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Global TF Kernel (Python 3)",
   "language": "python",
   "name": "global-tf-python-3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
