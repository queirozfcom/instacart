{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### forked from https://www.kaggle.com/znielsen/test-instacart-analysis/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f077e7a9110d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m \u001b[0;31m# text preprocessing & manipulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m \u001b[0;31m# plotting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m \u001b[0;31m# plotting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfunctools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpartial\u001b[0m \u001b[0;31m# to reduce df memory consumption by applying to_numeric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import nltk # text preprocessing & manipulation\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import seaborn as sns # plotting\n",
    "\n",
    "from functools import partial # to reduce df memory consumption by applying to_numeric\n",
    "\n",
    "color = sns.color_palette() # adjusting plotting style\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # silence annoying warnings\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "# Import all the data\n",
    "aisles = pd.read_csv('../input/aisles.csv', engine='c')\n",
    "departments = pd.read_csv('../input/departments.csv', engine='c')\n",
    "products = pd.read_csv('../input/products.csv', engine='c')\n",
    "\n",
    "op_prior = pd.read_csv('../input/order_products__prior.csv', engine='c', \n",
    "                       dtype={'order_id': np.int32, \n",
    "                              'product_id': np.int32, \n",
    "                              'add_to_cart_order': np.int16, \n",
    "                              'reordered': np.int8})\n",
    "                              \n",
    "op_train = pd.read_csv('../input/order_products__train.csv', engine='c', \n",
    "                       dtype={'order_id': np.int32, 'product_id': np.int32, \n",
    "                              'add_to_cart_order': np.int16, 'reordered': np.int8})\n",
    "\n",
    "# orders\n",
    "orders = pd.read_csv('../input/orders.csv', engine='c', dtype={'order_id': np.int32, \n",
    "                                                           'user_id': np.int32, \n",
    "                                                           'order_number': np.int32, \n",
    "                                                           'order_dow': np.int8, \n",
    "                                                           'order_hour_of_day': np.int8, \n",
    "                                                           'days_since_prior_order': np.float16})\n",
    "\n",
    "# test dataset (submission)\n",
    "test = pd.read_csv('../input/sample_submission.csv', engine='c')\n",
    "\n",
    "\n",
    "#Add a field to calculate the sum of times an item was reordered\n",
    "products['rsum']=op_train.groupby('product_id')['reordered'].sum()\n",
    "#Add a field to calculate the total times the item could have been reordered\n",
    "products['rtotal']=op_train.groupby('product_id')['reordered'].count()\n",
    "#Add a field to calculate the probability that the item was reordered\n",
    "products['prob']=products['rsum']/products['rtotal']\n",
    "\n",
    "\n",
    "#Merge all of the details into a goods page\n",
    "goods = pd.merge(left=pd.merge(left=products, right=departments, how='left'), right=aisles, how='left')\n",
    "# to retain '-' and make product names more \"standard\"\n",
    "goods.product_name = goods.product_name.str.replace(' ', '_').str.lower() \n",
    "\n",
    "\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "# merge train and prior together iteratively, to fit into 8GB kernel RAM\n",
    "# split df indexes into parts\n",
    "indexes = np.linspace(0, len(op_prior), num=10, dtype=np.int32)\n",
    "\n",
    "# initialize it with train dataset\n",
    "order_details = pd.merge(\n",
    "                left=op_train,\n",
    "                 right=orders, \n",
    "                 how='left', \n",
    "                 on='order_id'\n",
    "        ).apply(partial(pd.to_numeric, errors='ignore', downcast='integer'))\n",
    "\n",
    "# add order hierarchy\n",
    "order_details = pd.merge(\n",
    "                left=order_details,\n",
    "                right=goods[['product_id', \n",
    "                             'aisle_id', \n",
    "                             'department_id',\n",
    "                             'prob']].apply(partial(pd.to_numeric, ##Added the 'prob'\n",
    "                                                             errors='ignore', \n",
    "                                                             downcast='integer')),\n",
    "                how='left',\n",
    "                on='product_id'\n",
    ")\n",
    "\n",
    "print(order_details.shape, op_train.shape)\n",
    "\n",
    "# delete (redundant now) dataframes\n",
    "del op_train\n",
    "\n",
    "print(order_details.head())\n",
    "\n",
    "#%%time\n",
    "# update by small portions\n",
    "for i in range(len(indexes)-1):\n",
    "    order_details = pd.concat(\n",
    "        [   \n",
    "            order_details,\n",
    "            pd.merge(left=pd.merge(\n",
    "                            left=op_prior.loc[indexes[i]:indexes[i+1], :],\n",
    "                            right=goods[['product_id', \n",
    "                                         'aisle_id', \n",
    "                                         'department_id' ]].apply(partial(pd.to_numeric, \n",
    "                                                                          errors='ignore', \n",
    "                                                                          downcast='integer')),\n",
    "                            how='left',\n",
    "                            on='product_id'\n",
    "                            ),\n",
    "                     right=orders, \n",
    "                     how='left', \n",
    "                     on='order_id'\n",
    "                ) #.apply(partial(pd.to_numeric, errors='ignore', downcast='integer'))\n",
    "        ]\n",
    "    )\n",
    "        \n",
    "print('Datafame length: {}'.format(order_details.shape[0]))\n",
    "print('Memory consumption: {:.2f} Mb'.format(sum(order_details.memory_usage(index=True, \n",
    "                                                                         deep=True) / 2**20)))\n",
    "# check dtypes to see if we use memory effectively\n",
    "print(order_details.dtypes)\n",
    "\n",
    "# make sure we didn't forget to retain test dataset :D\n",
    "test_orders = orders[orders.eval_set == 'test']\n",
    "\n",
    "# delete (redundant now) dataframes\n",
    "del op_prior, orders\n",
    "\n",
    "test_history = order_details[(order_details.user_id.isin(test_orders.user_id))]\n",
    "last_orders = test_history.groupby('user_id')['order_number'].max()\n",
    "\n",
    "def get_last_orders_reordered():\n",
    "    t = pd.merge(\n",
    "            left=pd.merge(\n",
    "                    left=last_orders.reset_index(),\n",
    "                    right=test_history[test_history.reordered == 1],\n",
    "                    how='left',\n",
    "                    on=['user_id', 'order_number']\n",
    "                )[['user_id', 'product_id']],\n",
    "            right=test_orders[['user_id', 'order_id']],\n",
    "            how='left',\n",
    "            on='user_id'\n",
    "        ).fillna(-1).groupby('order_id')['product_id'].apply(lambda x: ' '.join([str(int(e)) for e in set(x)]) \n",
    "                                                  ).reset_index().replace(to_replace='-1', \n",
    "                                                                          value='None')\n",
    "    t.columns = ['order_id', 'products']\n",
    "    return t\n",
    "\n",
    "# save submission\n",
    "get_last_orders_reordered().to_csv('last_order_reordered_only.csv', \n",
    "                         encoding='utf-8', \n",
    "                         index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Global TF Kernel (Python 3)",
   "language": "python",
   "name": "global-tf-python-3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
